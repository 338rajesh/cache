[
  {
    "objectID": "src/uq/mcmc.html",
    "href": "src/uq/mcmc.html",
    "title": "Monte Carlo Methods for Uncertainty Quantification",
    "section": "",
    "text": "Monte Carlo (MC) methods are a class of computational algorithms that rely on repeated random sampling to obtain numerical results. They are widely used in uncertainty quantification to estimate the expected value, variance, and other statistical properties of a model’s output when the input parameters are uncertain. The basic idea is to:\n\nGenerate random samples in the input space\nRun (deterministic) simulations or calculations for each of these random samples\nSummarize the results using statistics (e.g., mean, variance, confidence intervals) to quantify the uncertainty in the output\n\n\n\nMC methods rest on the principle of the law of large numbers, which states that as the number of samples increases, the sample average converges to the expected value. This means that with enough samples, we can get an accurate estimate of the uncertainty in our model’s predictions.\n\nStrong Law of Large Numbers: The sample average converges to the expected value almost surely (with probability 1).\n\n\\[\nPr(\\lim_{n \\to \\infty} \\bar{X}_n = \\mu) = 1 \\quad \\text{almost surely}\n\\]\n\nWeak Law of Large Numbers: The probability of the absolute difference between the sample average and the expected value being smaller than any small positive value \\(\\epsilon\\) approaches 1 as the number of samples goes to infinity.\n\n\\[\n\\lim_{n \\to \\infty} Pr(|\\bar{X}_n - \\mu| &lt; \\epsilon) = 1 \\quad \\text{for a small value } \\epsilon &gt; 0\n\\]\nLet \\(X_1, X_2, ..., X_n\\) be a sequence of independent and identically distributed (i.i.d.) random variables with expected value \\(\\mu\\) and variance \\(\\sigma^2\\). According to LLN, as \\(n\\) increases, the sample average \\(\\bar{X}_n\\) converges to \\(\\mu\\).\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n\\]\nVariance of the sample average can be used to understand the convergence rate. The following formula shows that the variance of the sample average decreases as the number of samples increases:\n\\[\nVar(\\bar{X}_n) = Var(\\frac{1}{n} \\sum_{i=1}^{n} X_i) = \\frac{1}{n^2} \\sum_{i=1}^{n} Var(X_i) = \\frac{\\sigma^2}{n}\n\\]\n\n\n\nFrom law of large numbers:\n\\[\n\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f_{X} (x) dx \\approx \\frac{1}{N} \\sum_{i=1}^{N} X_i\n\\]\nWhere \\(X_i\\) are i.i.d. samples drawn from the distribution of \\(X\\). The accuracy of this approximation improves as \\(N\\) increases, and the variance of the estimate decreases as \\(\\sigma^2 / N\\).\nMonte Carlo simulation is nothing but the process of simulating a large number of realizations of a random variable and then evaluating its average value to estimate the expected value.\nHere, the random variable \\(X\\) can be function of another random variable or a vector of random variables. Let \\(g\\) is a function that maps a random variable \\(X\\) to another random variable \\(Y\\), i.e., \\(Y = g(X)\\). When \\(g\\) takes a simple analytical form and invertible, we can derive the distribution of \\(Y\\) from the distribution of \\(X\\) using methods like change of variables. However, when \\(g\\) is complex or non-invertible, it becomes difficult to derive the distribution of \\(Y\\) analytically. In such cases, we can use Monte Carlo simulation to estimate the expected value of \\(Y\\).\n\\[\n\\mathbb{E}[Y] = \\mathbb{E}[g(X)] = \\int_{-\\infty}^{\\infty} g(x) f_{X} (x) dx \\approx \\frac{1}{N} \\sum_{i=1}^{N} g(X_i)\n\\]\nWhere \\(X_i\\) are i.i.d. samples drawn from the distribution of \\(X\\). The accuracy of this approximation improves as \\(N\\) increases, and the variance of the estimate decreases as \\(\\sigma^2 / N\\), where \\(\\sigma^2\\) is the variance of \\(g(X)\\).\n\n\n\nFor any functionor model \\(g: \\mathbb{R}^n \\rightarrow Y\\), that takes random variables as input with known probability distribution, one can estimate the expected value of the output distribution using the following Monte Carlo steps:\n\nGenerate \\(N\\) i.i.d. samples \\(`\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ..., \\boldsymbol{x}_{N}`\\) from the known joint density function \\(`{f}_{\\boldsymbol{X}}(\\boldsymbol{x})`\\) of the input random vector \\(`\\boldsymbol{X}`\\).\nFunction/model evaluation: For each sample \\(\\boldsymbol{x}_i\\), compute the corresponding output \\(y_i = g(\\boldsymbol{x}_i)\\). This step involves running the deterministic model or function for each of the generated samples.\nApply Monte Carlo averaging to estimate the expected value of the output distribution:\n\n\\[\n\\mathbb{E}[Y] = \\int_{-\\infty}^{\\infty} y f_{Y} (y) dy \\approx \\frac{1}{N} \\sum_{i=1}^{N} g(\\boldsymbol{x}_i)\n\\]",
    "crumbs": [
      "Home",
      "Uncertainty Quantifcation",
      "Monte Carlo Methods for Uncertainty Quantification"
    ]
  },
  {
    "objectID": "src/uq/mcmc.html#law-of-large-numbers",
    "href": "src/uq/mcmc.html#law-of-large-numbers",
    "title": "Monte Carlo Methods for Uncertainty Quantification",
    "section": "",
    "text": "MC methods rest on the principle of the law of large numbers, which states that as the number of samples increases, the sample average converges to the expected value. This means that with enough samples, we can get an accurate estimate of the uncertainty in our model’s predictions.\n\nStrong Law of Large Numbers: The sample average converges to the expected value almost surely (with probability 1).\n\n\\[\nPr(\\lim_{n \\to \\infty} \\bar{X}_n = \\mu) = 1 \\quad \\text{almost surely}\n\\]\n\nWeak Law of Large Numbers: The probability of the absolute difference between the sample average and the expected value being smaller than any small positive value \\(\\epsilon\\) approaches 1 as the number of samples goes to infinity.\n\n\\[\n\\lim_{n \\to \\infty} Pr(|\\bar{X}_n - \\mu| &lt; \\epsilon) = 1 \\quad \\text{for a small value } \\epsilon &gt; 0\n\\]\nLet \\(X_1, X_2, ..., X_n\\) be a sequence of independent and identically distributed (i.i.d.) random variables with expected value \\(\\mu\\) and variance \\(\\sigma^2\\). According to LLN, as \\(n\\) increases, the sample average \\(\\bar{X}_n\\) converges to \\(\\mu\\).\n\\[\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n\\]\nVariance of the sample average can be used to understand the convergence rate. The following formula shows that the variance of the sample average decreases as the number of samples increases:\n\\[\nVar(\\bar{X}_n) = Var(\\frac{1}{n} \\sum_{i=1}^{n} X_i) = \\frac{1}{n^2} \\sum_{i=1}^{n} Var(X_i) = \\frac{\\sigma^2}{n}\n\\]",
    "crumbs": [
      "Home",
      "Uncertainty Quantifcation",
      "Monte Carlo Methods for Uncertainty Quantification"
    ]
  },
  {
    "objectID": "src/uq/mcmc.html#monte-carlo-simulation",
    "href": "src/uq/mcmc.html#monte-carlo-simulation",
    "title": "Monte Carlo Methods for Uncertainty Quantification",
    "section": "",
    "text": "From law of large numbers:\n\\[\n\\mathbb{E}[X] = \\int_{-\\infty}^{\\infty} x f_{X} (x) dx \\approx \\frac{1}{N} \\sum_{i=1}^{N} X_i\n\\]\nWhere \\(X_i\\) are i.i.d. samples drawn from the distribution of \\(X\\). The accuracy of this approximation improves as \\(N\\) increases, and the variance of the estimate decreases as \\(\\sigma^2 / N\\).\nMonte Carlo simulation is nothing but the process of simulating a large number of realizations of a random variable and then evaluating its average value to estimate the expected value.\nHere, the random variable \\(X\\) can be function of another random variable or a vector of random variables. Let \\(g\\) is a function that maps a random variable \\(X\\) to another random variable \\(Y\\), i.e., \\(Y = g(X)\\). When \\(g\\) takes a simple analytical form and invertible, we can derive the distribution of \\(Y\\) from the distribution of \\(X\\) using methods like change of variables. However, when \\(g\\) is complex or non-invertible, it becomes difficult to derive the distribution of \\(Y\\) analytically. In such cases, we can use Monte Carlo simulation to estimate the expected value of \\(Y\\).\n\\[\n\\mathbb{E}[Y] = \\mathbb{E}[g(X)] = \\int_{-\\infty}^{\\infty} g(x) f_{X} (x) dx \\approx \\frac{1}{N} \\sum_{i=1}^{N} g(X_i)\n\\]\nWhere \\(X_i\\) are i.i.d. samples drawn from the distribution of \\(X\\). The accuracy of this approximation improves as \\(N\\) increases, and the variance of the estimate decreases as \\(\\sigma^2 / N\\), where \\(\\sigma^2\\) is the variance of \\(g(X)\\).",
    "crumbs": [
      "Home",
      "Uncertainty Quantifcation",
      "Monte Carlo Methods for Uncertainty Quantification"
    ]
  },
  {
    "objectID": "src/uq/mcmc.html#refined-standard-steps",
    "href": "src/uq/mcmc.html#refined-standard-steps",
    "title": "Monte Carlo Methods for Uncertainty Quantification",
    "section": "",
    "text": "For any functionor model \\(g: \\mathbb{R}^n \\rightarrow Y\\), that takes random variables as input with known probability distribution, one can estimate the expected value of the output distribution using the following Monte Carlo steps:\n\nGenerate \\(N\\) i.i.d. samples \\(`\\boldsymbol{x}_{1}, \\boldsymbol{x}_{2}, ..., \\boldsymbol{x}_{N}`\\) from the known joint density function \\(`{f}_{\\boldsymbol{X}}(\\boldsymbol{x})`\\) of the input random vector \\(`\\boldsymbol{X}`\\).\nFunction/model evaluation: For each sample \\(\\boldsymbol{x}_i\\), compute the corresponding output \\(y_i = g(\\boldsymbol{x}_i)\\). This step involves running the deterministic model or function for each of the generated samples.\nApply Monte Carlo averaging to estimate the expected value of the output distribution:\n\n\\[\n\\mathbb{E}[Y] = \\int_{-\\infty}^{\\infty} y f_{Y} (y) dy \\approx \\frac{1}{N} \\sum_{i=1}^{N} g(\\boldsymbol{x}_i)\n\\]",
    "crumbs": [
      "Home",
      "Uncertainty Quantifcation",
      "Monte Carlo Methods for Uncertainty Quantification"
    ]
  },
  {
    "objectID": "src/machine_learning/neural_odes.html",
    "href": "src/machine_learning/neural_odes.html",
    "title": "Neural Ordinary Differential Equations (Neural ODEs)",
    "section": "",
    "text": "Neural Ordinary Differential Equations (Neural ODEs) introduced by Chen et al. in 2018, model the evolution of a system’s state over time using a continuous function parameterized by a neural network.\nIn a standard neural network, the hidden state is represented as a discrete sequence of layers as shown below. These updates are like Euler’s discretization of a continuous transformation.\n\\[\n\\boldsymbol{h}_{t+1} = \\boldsymbol{h}_t + f(\\boldsymbol{h}_t, \\theta_t); \\;\\; t = 0, 1, ..., T\n\\]\nIn the limit as the step size goes to zero, this can be represented as a continuous transformation of the hidden state:\n\\[\n\\frac{d\\boldsymbol{h}}{dt} = f(h(t), t, \\theta)\n\\]\nUsing the neural ODE framework, a neural network is used to find the function \\(f\\) that determines the dynamics (or the velocity field) of the system. Then, the ODE relating the hidden state \\(\\boldsymbol{h}\\) with function \\(f\\) is solved using an ODE solver (e.g., torchdiffeq.odeint) to compute the output \\(\\boldsymbol{h}(T)\\) from the input \\(\\boldsymbol{h}(0)\\).\nInherently, ODE solver enforces the following:\n\\[\nX(t_k) = X(0) + \\int_{0}^{t_k} f(X(s), s, \\theta) ds\n\\]\n\n\\(\\boldsymbol{X}(0)\\) is the input layer, and \\(\\boldsymbol{X}(T)\\) is the output layer.\n\n\n\nAccording to the original paper:\n\nMemory Efficiency: Neural ODEs can be more memory efficient than traditional deep networks, as they do not require storing intermediate activations for backpropagation. Instead, they use the adjoint method to compute gradients, there by having a constant memory cost as a function of the network depth.\nAdaptive Computation: Depending on the complexity of the input, and the desired accuracy, Neural ODEs can adaptively choose the number of function evaluations needed to compute the output, which can lead to faster inference for simpler inputs.\nContinuous-Time Modeling: Neural ODEs naturally model continuous-time processes, containing observations at irregular time intervals.\nScalable and invertible normalizing flows\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nStandard NN\nNeural ODEs\n\n\n\n\nDepth\nNumber of layers\nIntegration time, number of function evaluations determined by the solver tolerance\n\n\nContinuity\nDiscrete, \\(h_{t+1} = f(h_t, \\theta)\\)\nContinuous, \\(\\frac{dh}{dt} = f(h(t), t, \\theta)\\)\n\n\nGradient\nBackpropagation through layers\nAdjoint method for gradient computation\n\n\nStep size\nFixed\nAdaptive\n\n\nForward pass\nthrough layers\nthrough ODE solver, Ex: using torchdiffeq.odeint\n\n\nBackward pass\nthrough layers\nthrough ODE solver, using adjoint method\n\n\nMemory cost\n\\(O(L)\\)\n\\(O(1)\\), it just stores the current state and the end points of the integration interval\n\n\nFunction \\(\\mathcal{f}\\)\nrepresents transformation mapping from input to output\nveclocity field that defines the dynamics of the system\n\n\n\n\n\n\n\n\nLet’s build a model that learns velocity field that governs the motion of points on a 2D curve such that the overall shape follows a specific geometric evolution. In this example, we will use a simple ellipse that expands and contracts over time, simulating a breathing motion whose aspect ratio changes according to the following function:\n\\[\n\\beta(t) = \\frac{1}{2}\\left[(\\beta_0 + \\frac{1}{\\beta_0}) + (\\beta_0 - \\frac{1}{\\beta_0})\\cos(\\frac{\\pi t}{T}) \\right]; \\quad t = 0, 1, ..., T \\\\\n\\]\n\n\n\nInitial state (\\(t=0\\)): An ellipse with aspect ratio \\(\\beta_0\\)\nIntermediate states: We have the observations of the curve at different time steps, possibly at irregular intervals. We want to learn the underlying velocity field that governs this motion.\nFinal state (\\(t=T\\)): The ellipse reaches opposite aspect ratio \\(\\beta_T = 1/\\beta_0\\).\nThe area of the ellipse is conserved over time.\nEach point on the curve maps to a new position at each time step, following the velocity field defined by the Neural ODE.\n\n\n\n\n\nNon-autonomous vector field (explicit time dependence) that governs the motion of points on the curve.\nConservation of topology (no crossing of trajectories)\nResolution invariance (the same curve should be obtained regardless of the number of points sampled on the curve)\n\n\n\n\n\nDefine a neural network to find the function \\(f_{\\theta}(X, t):\\mathbb{R}^2 \\times \\mathbb{R} \\rightarrow \\mathbb{R}^2\\), that determines the velocity field.\nThis leads to the ODE: \\(\\frac{dX}{dt} = f_{\\theta}(X, t)\\), where \\(X\\) is the set of points on the curve.\nUse an ODE solver (e.g., torchdiffeq.odeint) to compute the output \\(X(T)\\) from the input \\(X(0)\\).\nLoss function: Mean squared error between the predicted curve at time \\(T\\) and the true curve at time \\(T\\).\n\n\\[\n\\mathcal{L}(\\theta) = \\frac{1}{NK} \\sum_{i=1}^{N} \\sum_{k=1}^{K} \\| X_i^{\\theta}(t_k) - X_i^{\\text{true}}(t_k) \\|^2\n\\]\n\n\n\n\\[\n\\dfrac{x^2}{a(t)^2} + \\dfrac{y^2}{b(t)^2} = 1 \\\\\n\\]\nAssuming the ellipse is centered at the origin, parametrized by the angle \\(\\theta \\in [0, 2\\pi)\\), the coordinates of points on the ellipse can be expressed as:\n\\[\nx(t, \\theta) = a(t) \\cos{\\theta} \\\\\ny(t, \\theta) = b(t) \\sin{\\theta}\n\\]\nWhere \\(a(t)\\) and \\(b(t)\\) are the semi-major and semi-minor axes of the ellipse at time \\(t\\). The aspect ratio \\(\\beta(t)\\) is defined as:\n\\[\n\\beta(t) = \\frac{a(t)}{b(t)} \\\\\n\\beta(0) = \\beta_0 \\\\\n\\beta(T) = \\frac{1}{\\beta_0}\n\\]\nAs the area of the ellipse is conserved, we have:\n\\[\n\\begin{align*}\nA &= \\pi a(t) b(t) = \\text{constant} \\\\\n\\Rightarrow a(t) b(t) &= A / \\pi = \\xi ^ 2 \\\\\n\\Rightarrow a(t) &= \\xi \\sqrt{\\beta(t)} \\\\\n\\Rightarrow b(t) &= \\frac{\\xi}{\\sqrt{\\beta(t)}} \\\\\nx(t, \\theta) &= \\xi \\sqrt{\\beta(t)} \\cos{\\theta} \\\\\ny(t, \\theta) &= \\frac{\\xi}{\\sqrt{\\beta(t)}} \\sin{\\theta} \\\\\n\\end{align*}\n\\]\nDifferentiating the coordinates with respect to time to get the velocity field:\n\\[\n\\begin{align*}\n\\frac{dx}{dt} &= \\frac{d}{dt} (\\xi \\sqrt{\\beta(t)} \\cos{\\theta}) \\\\\n&= \\xi \\cos{\\theta} \\frac{d}{dt} \\sqrt{\\beta(t)} \\\\\n&= \\frac{\\xi}{2} \\cos{\\theta} \\frac{\\beta'(t)}{\\sqrt{\\beta(t)}} \\\\\n\\Rightarrow \\frac{dx}{dt} &= \\frac{x}{2} \\frac{\\beta'(t)}{\\beta(t)} \\\\\n\\end{align*}\n\\]\nSimilarly for \\(y\\):\n\\[\n\\begin{align*}\n\\frac{dy}{dt} &= \\frac{d}{dt} \\left( \\frac{\\xi}{\\sqrt{\\beta(t)}} \\sin{\\theta} \\right) \\\\\n&= -\\frac{\\xi}{2} \\sin{\\theta} \\frac{\\beta'(t)}{\\beta(t)\\sqrt{\\beta(t)}} \\\\\n\\Rightarrow \\frac{dy}{dt} &= -\\frac{y}{2} \\frac{\\beta'(t)}{\\beta(t)}\n\\end{align*}\n\\]\nHence, the velocity field governing the motion of points on the curve can be expressed as:\n\\[\n\\begin{align*}\n\\frac{d}{dt} \\begin{pmatrix} x \\\\ y \\end{pmatrix} &= \\alpha(t) \\begin{pmatrix} x \\\\ -y \\end{pmatrix} \\\\\n&= \\frac{\\beta'(t)}{2\\beta(t)} \\begin{pmatrix} x \\\\ -y \\end{pmatrix}\n\\end{align*}\n\\]\nThe neural ODE should learn this time-varying velocity field that governs the motion of points on the curve, allowing it to reconstruct the breathing ellipse dynamics from the observed data.\n\n\n\n\n\nAccording to the original paper:\n\nMinibatching\nUnique Solutions\nManual tolerance Setting\nErrors in the reconstruction of forward trajectories",
    "crumbs": [
      "Home",
      "Machine Learning",
      "Neural Ordinary Differential Equations (Neural ODEs)"
    ]
  },
  {
    "objectID": "src/machine_learning/neural_odes.html#advantages-of-neural-odes",
    "href": "src/machine_learning/neural_odes.html#advantages-of-neural-odes",
    "title": "Neural Ordinary Differential Equations (Neural ODEs)",
    "section": "",
    "text": "According to the original paper:\n\nMemory Efficiency: Neural ODEs can be more memory efficient than traditional deep networks, as they do not require storing intermediate activations for backpropagation. Instead, they use the adjoint method to compute gradients, there by having a constant memory cost as a function of the network depth.\nAdaptive Computation: Depending on the complexity of the input, and the desired accuracy, Neural ODEs can adaptively choose the number of function evaluations needed to compute the output, which can lead to faster inference for simpler inputs.\nContinuous-Time Modeling: Neural ODEs naturally model continuous-time processes, containing observations at irregular time intervals.\nScalable and invertible normalizing flows",
    "crumbs": [
      "Home",
      "Machine Learning",
      "Neural Ordinary Differential Equations (Neural ODEs)"
    ]
  },
  {
    "objectID": "src/machine_learning/neural_odes.html#standard-nn-leftrightarrow-neural-odes",
    "href": "src/machine_learning/neural_odes.html#standard-nn-leftrightarrow-neural-odes",
    "title": "Neural Ordinary Differential Equations (Neural ODEs)",
    "section": "",
    "text": "Feature\nStandard NN\nNeural ODEs\n\n\n\n\nDepth\nNumber of layers\nIntegration time, number of function evaluations determined by the solver tolerance\n\n\nContinuity\nDiscrete, \\(h_{t+1} = f(h_t, \\theta)\\)\nContinuous, \\(\\frac{dh}{dt} = f(h(t), t, \\theta)\\)\n\n\nGradient\nBackpropagation through layers\nAdjoint method for gradient computation\n\n\nStep size\nFixed\nAdaptive\n\n\nForward pass\nthrough layers\nthrough ODE solver, Ex: using torchdiffeq.odeint\n\n\nBackward pass\nthrough layers\nthrough ODE solver, using adjoint method\n\n\nMemory cost\n\\(O(L)\\)\n\\(O(1)\\), it just stores the current state and the end points of the integration interval\n\n\nFunction \\(\\mathcal{f}\\)\nrepresents transformation mapping from input to output\nveclocity field that defines the dynamics of the system",
    "crumbs": [
      "Home",
      "Machine Learning",
      "Neural Ordinary Differential Equations (Neural ODEs)"
    ]
  },
  {
    "objectID": "src/machine_learning/neural_odes.html#a-simple-example-of-a-neural-ode",
    "href": "src/machine_learning/neural_odes.html#a-simple-example-of-a-neural-ode",
    "title": "Neural Ordinary Differential Equations (Neural ODEs)",
    "section": "",
    "text": "Let’s build a model that learns velocity field that governs the motion of points on a 2D curve such that the overall shape follows a specific geometric evolution. In this example, we will use a simple ellipse that expands and contracts over time, simulating a breathing motion whose aspect ratio changes according to the following function:\n\\[\n\\beta(t) = \\frac{1}{2}\\left[(\\beta_0 + \\frac{1}{\\beta_0}) + (\\beta_0 - \\frac{1}{\\beta_0})\\cos(\\frac{\\pi t}{T}) \\right]; \\quad t = 0, 1, ..., T \\\\\n\\]\n\n\n\nInitial state (\\(t=0\\)): An ellipse with aspect ratio \\(\\beta_0\\)\nIntermediate states: We have the observations of the curve at different time steps, possibly at irregular intervals. We want to learn the underlying velocity field that governs this motion.\nFinal state (\\(t=T\\)): The ellipse reaches opposite aspect ratio \\(\\beta_T = 1/\\beta_0\\).\nThe area of the ellipse is conserved over time.\nEach point on the curve maps to a new position at each time step, following the velocity field defined by the Neural ODE.\n\n\n\n\n\nNon-autonomous vector field (explicit time dependence) that governs the motion of points on the curve.\nConservation of topology (no crossing of trajectories)\nResolution invariance (the same curve should be obtained regardless of the number of points sampled on the curve)\n\n\n\n\n\nDefine a neural network to find the function \\(f_{\\theta}(X, t):\\mathbb{R}^2 \\times \\mathbb{R} \\rightarrow \\mathbb{R}^2\\), that determines the velocity field.\nThis leads to the ODE: \\(\\frac{dX}{dt} = f_{\\theta}(X, t)\\), where \\(X\\) is the set of points on the curve.\nUse an ODE solver (e.g., torchdiffeq.odeint) to compute the output \\(X(T)\\) from the input \\(X(0)\\).\nLoss function: Mean squared error between the predicted curve at time \\(T\\) and the true curve at time \\(T\\).\n\n\\[\n\\mathcal{L}(\\theta) = \\frac{1}{NK} \\sum_{i=1}^{N} \\sum_{k=1}^{K} \\| X_i^{\\theta}(t_k) - X_i^{\\text{true}}(t_k) \\|^2\n\\]\n\n\n\n\\[\n\\dfrac{x^2}{a(t)^2} + \\dfrac{y^2}{b(t)^2} = 1 \\\\\n\\]\nAssuming the ellipse is centered at the origin, parametrized by the angle \\(\\theta \\in [0, 2\\pi)\\), the coordinates of points on the ellipse can be expressed as:\n\\[\nx(t, \\theta) = a(t) \\cos{\\theta} \\\\\ny(t, \\theta) = b(t) \\sin{\\theta}\n\\]\nWhere \\(a(t)\\) and \\(b(t)\\) are the semi-major and semi-minor axes of the ellipse at time \\(t\\). The aspect ratio \\(\\beta(t)\\) is defined as:\n\\[\n\\beta(t) = \\frac{a(t)}{b(t)} \\\\\n\\beta(0) = \\beta_0 \\\\\n\\beta(T) = \\frac{1}{\\beta_0}\n\\]\nAs the area of the ellipse is conserved, we have:\n\\[\n\\begin{align*}\nA &= \\pi a(t) b(t) = \\text{constant} \\\\\n\\Rightarrow a(t) b(t) &= A / \\pi = \\xi ^ 2 \\\\\n\\Rightarrow a(t) &= \\xi \\sqrt{\\beta(t)} \\\\\n\\Rightarrow b(t) &= \\frac{\\xi}{\\sqrt{\\beta(t)}} \\\\\nx(t, \\theta) &= \\xi \\sqrt{\\beta(t)} \\cos{\\theta} \\\\\ny(t, \\theta) &= \\frac{\\xi}{\\sqrt{\\beta(t)}} \\sin{\\theta} \\\\\n\\end{align*}\n\\]\nDifferentiating the coordinates with respect to time to get the velocity field:\n\\[\n\\begin{align*}\n\\frac{dx}{dt} &= \\frac{d}{dt} (\\xi \\sqrt{\\beta(t)} \\cos{\\theta}) \\\\\n&= \\xi \\cos{\\theta} \\frac{d}{dt} \\sqrt{\\beta(t)} \\\\\n&= \\frac{\\xi}{2} \\cos{\\theta} \\frac{\\beta'(t)}{\\sqrt{\\beta(t)}} \\\\\n\\Rightarrow \\frac{dx}{dt} &= \\frac{x}{2} \\frac{\\beta'(t)}{\\beta(t)} \\\\\n\\end{align*}\n\\]\nSimilarly for \\(y\\):\n\\[\n\\begin{align*}\n\\frac{dy}{dt} &= \\frac{d}{dt} \\left( \\frac{\\xi}{\\sqrt{\\beta(t)}} \\sin{\\theta} \\right) \\\\\n&= -\\frac{\\xi}{2} \\sin{\\theta} \\frac{\\beta'(t)}{\\beta(t)\\sqrt{\\beta(t)}} \\\\\n\\Rightarrow \\frac{dy}{dt} &= -\\frac{y}{2} \\frac{\\beta'(t)}{\\beta(t)}\n\\end{align*}\n\\]\nHence, the velocity field governing the motion of points on the curve can be expressed as:\n\\[\n\\begin{align*}\n\\frac{d}{dt} \\begin{pmatrix} x \\\\ y \\end{pmatrix} &= \\alpha(t) \\begin{pmatrix} x \\\\ -y \\end{pmatrix} \\\\\n&= \\frac{\\beta'(t)}{2\\beta(t)} \\begin{pmatrix} x \\\\ -y \\end{pmatrix}\n\\end{align*}\n\\]\nThe neural ODE should learn this time-varying velocity field that governs the motion of points on the curve, allowing it to reconstruct the breathing ellipse dynamics from the observed data.",
    "crumbs": [
      "Home",
      "Machine Learning",
      "Neural Ordinary Differential Equations (Neural ODEs)"
    ]
  },
  {
    "objectID": "src/machine_learning/neural_odes.html#scopelimitations-of-neural-odes",
    "href": "src/machine_learning/neural_odes.html#scopelimitations-of-neural-odes",
    "title": "Neural Ordinary Differential Equations (Neural ODEs)",
    "section": "",
    "text": "According to the original paper:\n\nMinibatching\nUnique Solutions\nManual tolerance Setting\nErrors in the reconstruction of forward trajectories",
    "crumbs": [
      "Home",
      "Machine Learning",
      "Neural Ordinary Differential Equations (Neural ODEs)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cache!",
    "section": "",
    "text": "Hello, welcome to the cache!\nThis repository, as it named, is used as a cache to store notes on various topics that I have written or collected. These notes are typically prepared after reading new manuscripts, after completion of some technical courses, and after exploratory studies.\n\n\n\n\n\n\nImportantImportant\n\n\n\n\nIt is not intended to be a comprehensive collection of notes, but rather a personal repository for my own reference and learning. The content may be incomplete, partially incorrect, or outdated. Please read it with caution and verify the information from original sources when necessary."
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "All Notes",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nAuthor\n\n\n\n\n\n\n\n\nNeural Ordinary Differential Equations (Neural ODEs)\n\n\n \n\n\n\n\n\n\nResidual network block\n\n\n \n\n\n\n\n\n\nMonte Carlo Methods for Uncertainty Quantification\n\n\n \n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home",
      "All Notes"
    ]
  },
  {
    "objectID": "src/machine_learning/resnet.html",
    "href": "src/machine_learning/resnet.html",
    "title": "Residual network block",
    "section": "",
    "text": "Residual network block\nResnet block adds a skip connection to the output of a sequence of neural network layers, designed for addressing the vanishing gradient problem in deep neural networks.\nThe Resnet block can be represented mathematically as:\n\\[\ny = F(x) + x\n\\]\nWhere \\(F(x)\\) is the output of the sequence of layers, and \\(x\\) is the input to those layers. If there is a need to learn a more complex function, \\(F(x)\\) will capture that complexity. If not, \\(F(x)\\) can be zero, and the output will simply be the input \\(x\\), allowing for an identity mapping.\nHere, the word “residual” refers to the fact that the sequence of layers is learning the residual function \\(F(x)\\), which is the difference between the desired output and the input. This allows the network to learn more effectively, as it can focus on learning the residuals rather than trying to learn the entire mapping from input to output.\nThe gradient of the output with respect to the input can be expressed as:\n\\[\n\\frac{\\partial y}{\\partial x} = \\frac{\\partial F(x)}{\\partial x} + 1\n\\]\nIn some cases, the function \\(F(x)\\) may be very small, leading to very small gradients. Here, however the +1 term ensures becomes the bridge that allows the gradient to flow through the network, even when \\(F(x)\\) is small. This is one of the key reasons why Resnet blocks help mitigate the vanishing gradient problem in deep neural networks. Allowing smaller changes with \\(F(x)\\), while still maintaining a strong gradient flow through the skip connection, enables feature refinement and learning in deeper networks.",
    "crumbs": [
      "Home",
      "Machine Learning",
      "Residual network block"
    ]
  }
]